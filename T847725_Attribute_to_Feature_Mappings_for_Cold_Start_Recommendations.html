
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Attribute to Feature Mappings for Cold-Start Recommendations &#8212; coldstart-recsys</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Cold-Start Recommendations" href="L281872_Cold_Start_Recommendations.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">coldstart-recsys</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L281872_Cold_Start_Recommendations.html">
   Cold-Start Recommendations
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Attribute to Feature Mappings for Cold-Start Recommendations
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/T847725_Attribute_to_Feature_Mappings_for_Cold_Start_Recommendations.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/coldstart-recsys/main?urlpath=tree/docs/T847725_Attribute_to_Feature_Mappings_for_Cold_Start_Recommendations.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/sparsh-ai/coldstart-recsys/blob/main/docs/T847725_Attribute_to_Feature_Mappings_for_Cold_Start_Recommendations.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#datasets">
   Datasets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bpr">
   BPR
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling">
   Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#splitting">
   Splitting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parsing">
   Parsing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mapping">
   Mapping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#main">
   Main
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#runs">
   Runs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random">
     Random
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cbf-knn">
     CBF-KNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extra-notes">
   Extra Notes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example">
     Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loss-function">
     Loss function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#citations">
   Citations
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="attribute-to-feature-mappings-for-cold-start-recommendations">
<h1>Attribute to Feature Mappings for Cold-Start Recommendations<a class="headerlink" href="#attribute-to-feature-mappings-for-cold-start-recommendations" title="Permalink to this headline">¶</a></h1>
<div class="section" id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">attribute</span><span class="o">.</span><span class="n">txt</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing attribute.txt
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">feedback</span><span class="o">.</span><span class="n">txt</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span>
<span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Writing feedback.txt
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">exp</span><span class="p">,</span> <span class="n">log</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">exp</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span>
<span class="kn">import</span> <span class="nn">functools</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bpr">
<h2>BPR<a class="headerlink" href="#bpr" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BPRArgs</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                 <span class="n">bias_regularization</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">user_regularization</span><span class="o">=</span><span class="mf">0.0025</span><span class="p">,</span>
                 <span class="n">positive_item_regularization</span><span class="o">=</span><span class="mf">0.0025</span><span class="p">,</span>
                 <span class="n">negative_item_regularization</span><span class="o">=</span><span class="mf">0.00025</span><span class="p">,</span>
                 <span class="n">update_negative_item_factors</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularization</span> <span class="o">=</span> <span class="n">bias_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_regularization</span> <span class="o">=</span> <span class="n">user_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positive_item_regularization</span> <span class="o">=</span> <span class="n">positive_item_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">negative_item_regularization</span> <span class="o">=</span> <span class="n">negative_item_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_negative_item_factors</span> <span class="o">=</span> <span class="n">update_negative_item_factors</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BPR</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">D</span><span class="p">,</span><span class="n">args</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;initialise BPR matrix factorization model</span>
<span class="sd">        D: number of factors</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularization</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">bias_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_regularization</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">user_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positive_item_regularization</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">positive_item_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">negative_item_regularization</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">negative_item_regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_negative_item_factors</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">update_negative_item_factors</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">sampler</span><span class="p">,</span><span class="n">num_iters</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;train model</span>
<span class="sd">        data: user-item matrix as a scipy sparse matrix</span>
<span class="sd">              users and items are zero-indexed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">)</span>

        <span class="c1">#print &#39;initial loss = {0}&#39;.format(self.loss())</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="c1">#print &#39;starting iteration {0}&#39;.format(it)</span>
            <span class="k">for</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">sampler</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_factors</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iteration </span><span class="si">{0}</span><span class="s1">: loss = </span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">it</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span> <span class="o">=</span> <span class="n">dataidx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataidx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">create_loss_samples</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">create_loss_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># apply rule of thumb to decide num samples over which to compute loss</span>
        <span class="n">num_loss_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="n">sampler</span> <span class="o">=</span> <span class="n">UniformUserUniformItem</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">sampler</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span><span class="n">num_loss_samples</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">update_factors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">update_u</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">update_i</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;apply SGD update&quot;&quot;&quot;</span>
        <span class="n">update_j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_negative_item_factors</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> \
            <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">,:],</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">j</span><span class="p">,:])</span>

        <span class="c1">#XXX: maybe it should be exp(-x)/(1.0+exp(-x))</span>
        <span class="c1">#z = 1.0/(1.0+exp(x))</span>
        <span class="n">z</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

        <span class="c1"># update bias terms</span>
        <span class="k">if</span> <span class="n">update_i</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularization</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d</span>
        <span class="k">if</span> <span class="n">update_j</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="o">-</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularization</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d</span>

        <span class="k">if</span> <span class="n">update_u</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">j</span><span class="p">,:])</span><span class="o">*</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_regularization</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">,:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">,:]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">*</span><span class="n">d</span>
        <span class="k">if</span> <span class="n">update_i</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">,:]</span><span class="o">*</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">positive_item_regularization</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">*</span><span class="n">d</span>
        <span class="k">if</span> <span class="n">update_j</span><span class="p">:</span>
            <span class="n">d</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">,:]</span><span class="o">*</span><span class="n">z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative_item_regularization</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">j</span><span class="p">,:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">j</span><span class="p">,:]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">*</span><span class="n">d</span>

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">ranking_loss</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_samples</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
            <span class="c1">#it should be ln(1.0/(1.0+exp(-x)) according to thesis)</span>
            <span class="c1">#ranking_loss += 1.0/(1.0+exp(x))</span>
            <span class="n">ranking_loss</span> <span class="o">+=</span> <span class="n">log</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)))</span>

        <span class="n">complexity</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_samples</span><span class="p">:</span>
            <span class="n">complexity</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_regularization</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">])</span>
            <span class="n">complexity</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">positive_item_regularization</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">complexity</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">negative_item_regularization</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">j</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
            <span class="n">complexity</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularization</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">complexity</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularization</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>

        <span class="c1">#XXX: where does 0.5 come from? returns negative BPR-OPT so that it looks we are minimizing it</span>
        <span class="c1">#return ranking_loss + 0.5*complexity</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">ranking_loss</span> <span class="o">+</span> <span class="n">complexity</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sampling">
<h2>Sampling<a class="headerlink" href="#sampling" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Sampler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">max_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span> <span class="o">=</span> <span class="n">dataidx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataidx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">num_items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datannz</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">datannz</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">sample_user</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uniform_user</span><span class="p">()</span>
        <span class="n">num_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">])</span>
        <span class="k">assert</span><span class="p">(</span><span class="n">num_pos</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">num_pos</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">u</span>

    <span class="k">def</span> <span class="nf">sample_negative_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">user_items</span><span class="p">):</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">user_items</span><span class="p">:</span>
            <span class="n">j</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">j</span>

    <span class="k">def</span> <span class="nf">uniform_user</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">num_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">n</span>
        <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">UniformUserUniformItem</span><span class="p">(</span><span class="n">Sampler</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">max_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">max_samples</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datannz</span><span class="p">)):</span>
            <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uniform_user</span><span class="p">()</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span>
            <span class="c1"># sample positive item</span>
            <span class="n">num_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">num_pos</span><span class="o">&lt;=</span><span class="mi">0</span> <span class="ow">or</span> <span class="n">num_pos</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">):</span>
                <span class="c1">#throw bad user samples out</span>
                <span class="k">continue</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_negative_item</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">UniformUserUniformItemWithoutReplacement</span><span class="p">(</span><span class="n">Sampler</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">max_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">max_samples</span><span class="p">)</span>
        <span class="c1"># make a local copy of data as we&#39;re going to &quot;forget&quot; some entries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_dataidx</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datannz</span><span class="p">)):</span>
            <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uniform_user</span><span class="p">()</span>
            <span class="c1"># sample positive item without replacement if we can</span>
            <span class="n">user_items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">user_items</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="c1"># reset user data if it&#39;s all been sampled</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">local_dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">user_items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">user_items</span><span class="o">.</span><span class="n">size</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># forget this item so we don&#39;t sample it again for the same user</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">local_dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">user_items</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
            <span class="n">j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_negative_item</span><span class="p">(</span><span class="n">user_items</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ExternalSchedule</span><span class="p">(</span><span class="n">Sampler</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">filepath</span><span class="p">,</span><span class="n">index_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">filepath</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_offset</span> <span class="o">=</span> <span class="n">index_offset</span>

    <span class="k">def</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">max_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">dataidx</span><span class="p">,</span><span class="n">num_items</span><span class="p">,</span><span class="n">max_samples</span><span class="p">)</span>
        <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>  <span class="c1"># important!</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">[:</span><span class="n">num_samples</span><span class="p">]:</span>
            <span class="k">yield</span> <span class="n">u</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">index_offset</span><span class="p">,</span><span class="n">i</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">index_offset</span><span class="p">,</span><span class="n">j</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">index_offset</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="splitting">
<h2>Splitting<a class="headerlink" href="#splitting" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DataSplitter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">datamat</span><span class="p">,</span> <span class="n">attrmat</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">sp</span><span class="o">.</span><span class="n">isspmatrix_csc</span><span class="p">(</span><span class="n">datamat</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datamat</span> <span class="o">=</span> <span class="n">datamat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrmat</span> <span class="o">=</span> <span class="n">attrmat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">datamat</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">&lt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)]</span>
        <span class="c1">#random.shuffle(self.index)</span>

    <span class="k">def</span> <span class="nf">split_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">base</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">-</span><span class="n">base</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">))):</span>
                <span class="n">tmp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datamat</span><span class="o">.</span><span class="n">getcol</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">base</span><span class="o">+</span><span class="n">j</span><span class="p">]))</span>
            <span class="n">base</span> <span class="o">=</span> <span class="n">base</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span><span class="s2">&quot;csc&quot;</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">split_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">base</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">-</span><span class="n">base</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">))):</span>
                <span class="n">tmp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attrmat</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">base</span><span class="o">+</span><span class="n">j</span><span class="p">]])</span>
            <span class="n">base</span> <span class="o">=</span> <span class="n">base</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="parsing">
<h2>Parsing<a class="headerlink" href="#parsing" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>

<span class="k">class</span> <span class="nc">DataParser</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attrfile</span> <span class="o">=</span> <span class="n">attrfile</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

<span class="k">class</span> <span class="nc">Ml_100_Parser</span><span class="p">(</span><span class="n">DataParser</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">pass</span>
                
    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">class</span> <span class="nc">Ml_1M_Parser</span><span class="p">(</span><span class="n">DataParser</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">pass</span>
    <span class="c1"># example of training and testing with mapping functions</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mapping">
<h2>Mapping<a class="headerlink" href="#mapping" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">operator</span> <span class="k">as</span> <span class="nn">op</span>

<span class="k">def</span> <span class="nf">cmp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="c1"># return (a &gt; b) - (a &lt; b) </span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span><span class="c1">#.astype(np.float32)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span><span class="c1">#.astype(np.float32)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Mapper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bpr_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bpr_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">sp</span><span class="o">.</span><span class="n">isspmatrix_csc</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attr</span> <span class="o">=</span> <span class="n">attr</span>
        <span class="k">assert</span> <span class="n">attr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span>
        <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attrs</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">bpr_model</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span><span class="n">bpr_k</span><span class="p">][</span><span class="n">bpr_k</span><span class="o">!=</span><span class="kc">None</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">bpr_args</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bpr_args</span> <span class="o">=</span> <span class="n">BPRArgs</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02125</span><span class="p">,</span> <span class="mf">0.00355</span><span class="p">,</span> <span class="mf">0.00355</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bpr_args</span> <span class="o">=</span> <span class="n">bpr_args</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span> <span class="o">=</span> <span class="n">BPR</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_args</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span> <span class="o">=</span> <span class="n">bpr_model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span> <span class="o">=</span> <span class="n">bpr_model</span><span class="o">.</span><span class="n">D</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bpr_args</span> <span class="o">=</span> <span class="n">BPRArgs</span><span class="p">(</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> \
                <span class="n">bpr_model</span><span class="o">.</span><span class="n">bias_regularization</span><span class="p">,</span> \
                <span class="n">bpr_model</span><span class="o">.</span><span class="n">user_regularization</span><span class="p">,</span> \
                <span class="n">bpr_model</span><span class="o">.</span><span class="n">positive_item_regularization</span><span class="p">,</span> \
                <span class="n">bpr_model</span><span class="o">.</span><span class="n">negative_item_regularization</span><span class="p">,</span> \
                <span class="n">bpr_model</span><span class="o">.</span><span class="n">update_negative_item_factors</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">UniformUserUniformItem</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">train_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">sp</span><span class="o">.</span><span class="n">isspmatrix_csc</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">test_attr</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">tocsr</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span> <span class="o">=</span> <span class="n">test_attr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_dataidx</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_dataidx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cos_similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr_sqr_cache</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tattr_sqr_cache</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attr_sqr_cache</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tattr_sqr_cache</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">attr_sqr_cache</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="n">j</span><span class="p">])))</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tattr_sqr_cache</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span><span class="p">[</span><span class="n">j</span><span class="p">])))</span>

        <span class="n">similarity</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">):</span>
            <span class="n">similarity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tattr_sqr_cache</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr_sqr_cache</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">similarity</span>

    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="c1">#XXX: bpr models have no range bound, while its focus are pair-wise relationships, so it&#39;s hard to set a threshold and test accuracy</span>
        <span class="n">result</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span><span class="p">):</span>
            <span class="n">pred_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_predict</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
                <span class="n">posidx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">pred_i</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">&gt;=</span><span class="n">threshold</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="ow">in</span> <span class="n">posidx</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="n">pred_i</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">&lt;</span><span class="n">threshold</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">posidx</span><span class="p">)):</span>
                    <span class="n">result</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">result</span> <span class="o">/=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">prec_at_n</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prec_n</span><span class="p">):</span>
        <span class="c1">#precision of top-n recommended results, average across users</span>
        <span class="k">assert</span> <span class="n">prec_n</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span>
        <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">cand</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span><span class="p">):</span>
            <span class="n">pred_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_predict</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
                <span class="n">cand</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">pred_i</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">i</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="n">keyfunc</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">cmp_to_key</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="p">:</span> <span class="n">cmp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="n">cand</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">keyfunc</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">row_u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">prec_n</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">cand</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="n">row_u</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">tmp</span><span class="o">/</span><span class="n">prec_n</span>
        <span class="n">result</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">auc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#area under ROC curve, compute , average across users</span>
        <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span><span class="p">):</span>
            <span class="n">pred_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_predict</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
                <span class="n">pred</span><span class="p">[</span><span class="n">u</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_i</span><span class="p">[</span><span class="n">u</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">posidx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">posidx</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">posidx</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">pred</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">pred</span><span class="p">[</span><span class="n">u</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">&gt;=</span><span class="mi">0</span><span class="p">:</span>
                        <span class="n">tmp</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">real_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">posidx</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">tmp</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">real_pos</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_test_items</span><span class="o">-</span><span class="n">real_pos</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_users</span>
        <span class="k">return</span> <span class="n">result</span> 

    <span class="k">def</span> <span class="nf">cross_validation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cv_num_iters</span><span class="p">,</span> <span class="n">cv_set</span><span class="p">,</span> <span class="n">cv_folds</span><span class="p">):</span>
        <span class="n">origin_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="n">origin_attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span>
        <span class="n">origin_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span>
        <span class="n">splitter</span> <span class="o">=</span> <span class="n">DataSplitter</span><span class="p">(</span><span class="n">origin_data</span><span class="p">,</span> <span class="n">origin_attr</span><span class="p">,</span> <span class="n">cv_folds</span><span class="p">)</span>
        <span class="n">datamats</span> <span class="o">=</span> <span class="n">splitter</span><span class="o">.</span><span class="n">split_data</span><span class="p">()</span>
        <span class="n">attrmats</span> <span class="o">=</span> <span class="n">splitter</span><span class="o">.</span><span class="n">split_attr</span><span class="p">()</span>
        <span class="n">bestscore</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">bestpara</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">para</span> <span class="ow">in</span> <span class="n">cv_set</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_parameter</span><span class="p">(</span><span class="n">para</span><span class="p">)</span>
            <span class="n">avg_score</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validating parameter&quot;</span><span class="p">,</span><span class="n">para</span><span class="p">,</span><span class="s2">&quot;.........&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cv_folds</span><span class="p">):</span>
                <span class="n">tmp_data</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">datamats</span><span class="p">)</span>
                <span class="n">tmp_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">tmp_attr</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">attrmats</span><span class="p">)</span>
                <span class="n">tmp_attr</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tmp_data</span><span class="p">,</span><span class="s2">&quot;csc&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">tmp_attr</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">cv_num_iters</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test_init</span><span class="p">(</span><span class="n">datamats</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">attrmats</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="c1">#avg_score += self.accuracy()</span>
                <span class="n">cur_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prec_at_n</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;prec@5 of cross-validation fold&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s2">&quot;:&quot;</span><span class="p">,</span><span class="n">cur_score</span><span class="p">)</span>
                <span class="n">avg_score</span> <span class="o">+=</span> <span class="n">cur_score</span>
            <span class="n">avg_score</span> <span class="o">/=</span> <span class="n">cv_folds</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average score for parameter after cross-validation&quot;</span><span class="p">,</span><span class="n">para</span><span class="p">,</span><span class="s2">&quot;:&quot;</span><span class="p">,</span><span class="n">avg_score</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">avg_score</span> <span class="o">&gt;</span> <span class="n">bestscore</span><span class="p">):</span>
                <span class="n">bestpara</span> <span class="o">=</span> <span class="n">para</span>
                <span class="n">bestscore</span> <span class="o">=</span> <span class="n">avg_score</span>
        <span class="c1">#print(&quot;best parameter in cross-validation :&quot;, bestpara, &quot;with accuracy&quot;, bestscore)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;best parameter in cross-validation :&quot;</span><span class="p">,</span> <span class="n">bestpara</span><span class="p">,</span> <span class="s2">&quot;with prec@n&quot;</span><span class="p">,</span> <span class="n">bestscore</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">origin_data</span><span class="p">,</span> <span class="n">origin_attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">origin_model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">para</span>

<span class="k">class</span> <span class="nc">Map_KNN</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bpr_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">set_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_init</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">,</span> <span class="n">prec_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_init</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prec_at_n</span><span class="p">(</span><span class="n">prec_n</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">auc</span><span class="p">()]</span>   

    <span class="k">def</span> <span class="nf">test_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">cos_sim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos_similarity</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">cand</span> <span class="o">=</span> <span class="p">[(</span><span class="n">cos_sim</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)]</span>
        <span class="n">keyfunc</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">cmp_to_key</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">cmp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">cand</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">keyfunc</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1">#average new h from top-k h vectors, and predict with bpr</span>
        <span class="n">i_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">)</span>
        <span class="n">i_bias</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
            <span class="n">i_factors</span> <span class="o">+=</span> <span class="n">cand</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">item_factors</span><span class="p">[</span><span class="n">cand</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">1</span><span class="p">],:]</span>
            <span class="n">i_bias</span> <span class="o">+=</span> <span class="n">cand</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">item_bias</span><span class="p">[</span><span class="n">cand</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">sim_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cand</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">))</span>
        <span class="n">i_factors</span> <span class="o">/=</span> <span class="n">sim_sum</span>
        <span class="n">i_bias</span> <span class="o">/=</span> <span class="n">sim_sum</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i_bias</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">i_factors</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">Map_Linear</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bpr_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span> <span class="o">=</span> <span class="n">penalty_factor</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_init</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">)</span>
        <span class="c1">#train linear models for bpr_k column across attributes(X=attrs, Y=H[u])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attrs</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_attrs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias_b</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mapper Map_Linear trainning for iteration&quot;</span><span class="p">,</span><span class="n">it</span><span class="p">,</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">)))</span> \
                <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">item_factors</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)))</span>
            <span class="n">diff_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors_b</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias_b</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">item_bias</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors_b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff_b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors_b</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias_b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff_b</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">,</span> <span class="n">prec_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_init</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">)</span> 
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prec_at_n</span><span class="p">(</span><span class="n">prec_n</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">auc</span><span class="p">()]</span>   

    <span class="k">def</span> <span class="nf">test_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i_factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">i_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapper_bias_b</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors_b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i_bias</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">i_factors</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">set_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">para_set</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">para_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span> <span class="o">=</span> <span class="n">para_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">Map_BPR</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bpr_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">penalty_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span> <span class="o">=</span> <span class="n">penalty_factor</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_init</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">)</span>
        <span class="c1">#train linear models for bpr_k column across attributes(X=attrs, Y=H[u])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attrs</span><span class="p">))</span>
        <span class="c1">#self.mapper_bias = np.zeros((self.bpr_k, 1))</span>
        <span class="c1">#self.mapper_factors_b = np.random.random_sample(self.num_attrs)</span>
        <span class="c1">#self.mapper_bias_b = np.zeros(1)</span>
        <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mapper Map_BPR trainning for iteration&quot;</span><span class="p">,</span><span class="n">it</span><span class="p">,</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_items</span><span class="p">):</span>
                <span class="n">x_uij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
                <span class="c1">#XXX: maybe it should be exp(-x)/(1.0+exp(-x))</span>
                <span class="c1">#z = 1.0/(1.0+exp(x_uij))</span>
                <span class="n">z</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x_uij</span><span class="p">))</span>
                <span class="n">u_factor</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">,:])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_k</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                <span class="n">ij_diff</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attrs</span><span class="p">))</span>

                <span class="n">gradient</span> <span class="o">=</span> <span class="n">z</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u_factor</span><span class="p">,</span> <span class="n">ij_diff</span><span class="p">)</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span> \
                    <span class="n">gradient</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span> <span class="p">)</span>
                <span class="c1">#self.mapper_bias = self.learning_rate * ( \</span>
                <span class="c1">#    z * u_factor \</span>
                <span class="c1">#    - self.penalty_factor * self.mapper_bias )</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">,:]</span> \
            <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">)</span>
            <span class="c1">#\+self.mapper_bias )</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">,</span> <span class="n">prec_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_init</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">)</span> 
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prec_at_n</span><span class="p">(</span><span class="n">prec_n</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">auc</span><span class="p">()]</span>   

    <span class="k">def</span> <span class="nf">test_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mapper_factors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_attr</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="c1">#\+self.mapper_bias</span>
        <span class="c1">#no i_bias here because we didn&#39;t use actual h_i in trainning</span>
        <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpr_model</span><span class="o">.</span><span class="n">user_factors</span><span class="p">[</span><span class="n">u</span><span class="p">],</span> <span class="n">i_factors</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">set_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">para_set</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">para_set</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalty_factor</span> <span class="o">=</span> <span class="n">para_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">CBF_KNN</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bpr_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">set_parameter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">):</span>
        <span class="c1"># underlying bpr model is useless, so no need to train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_init</span><span class="p">()</span>
        <span class="k">pass</span> 

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">,</span> <span class="n">prec_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_init</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prec_at_n</span><span class="p">(</span><span class="n">prec_n</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">auc</span><span class="p">()]</span>   

    <span class="k">def</span> <span class="nf">test_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">cos_sim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos_similarity</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
            <span class="c1"># k is infinity by default</span>
            <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
                <span class="n">pred_j</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]:</span>
                    <span class="n">pred_j</span> <span class="o">+=</span> <span class="n">cos_sim</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_j</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">):</span>
                <span class="n">cand</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataidx</span><span class="p">[</span><span class="n">u</span><span class="p">]:</span>
                    <span class="n">cand</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cos_sim</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">cand</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
                <span class="n">pred_j</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
                    <span class="n">pred_j</span> <span class="o">+=</span> <span class="n">cand</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_j</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">Map_Random</span><span class="p">(</span><span class="n">Mapper</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bpr_args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_iters</span><span class="p">):</span>
        <span class="c1">#no need to train</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">,</span> <span class="n">prec_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_init</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_attr</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prec_at_n</span><span class="p">(</span><span class="n">prec_n</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">auc</span><span class="p">()]</span>   

    <span class="k">def</span> <span class="nf">test_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">max_score</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">*</span> <span class="n">max_score</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_users</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="main">
<h2>Main<a class="headerlink" href="#main" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">model_id</span><span class="p">):</span>
    <span class="c1">#all parameters needed setting are here</span>
    <span class="n">num_folds</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">bpr_args</span> <span class="o">=</span> <span class="n">BPRArgs</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.02125</span><span class="p">,</span> <span class="mf">0.00355</span><span class="p">,</span> <span class="mf">0.00355</span><span class="p">)</span>
    <span class="n">bpr_k</span> <span class="o">=</span> <span class="mi">24</span>
    <span class="n">cv_iters</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">cv_folds</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">num_iters</span> <span class="o">=</span> <span class="mi">20</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">csc_matrix</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;feedback.txt&#39;</span><span class="p">))</span>
    <span class="n">attr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;attribute.txt&#39;</span><span class="p">)</span>
    <span class="n">splitter</span> <span class="o">=</span> <span class="n">DataSplitter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span>
    <span class="n">datamats</span> <span class="o">=</span> <span class="n">splitter</span><span class="o">.</span><span class="n">split_data</span><span class="p">()</span>
    <span class="n">attrmats</span> <span class="o">=</span> <span class="n">splitter</span><span class="o">.</span><span class="n">split_attr</span><span class="p">()</span>

    <span class="k">assert</span> <span class="n">num_folds</span><span class="o">&gt;</span><span class="mi">1</span>
    <span class="k">assert</span> <span class="n">cv_folds</span><span class="o">&gt;</span><span class="mi">1</span>
    <span class="n">avg_prec</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">avg_auc</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1">#training &amp; testing</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_folds</span><span class="p">):</span>
        <span class="n">tmp_data</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">datamats</span><span class="p">)</span>
        <span class="n">tmp_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">tmp_attr</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">attrmats</span><span class="p">)</span>
        <span class="n">tmp_attr</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">model_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">cv_parameter_set</span> <span class="o">=</span> <span class="p">[(</span><span class="mf">0.03</span><span class="p">,</span><span class="mf">0.03</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.03</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.03</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)]</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">Map_BPR</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tmp_data</span><span class="p">,</span><span class="s2">&quot;csc&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">tmp_attr</span><span class="p">),</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">model_id</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">cv_parameter_set</span> <span class="o">=</span> <span class="p">[(</span><span class="mf">0.03</span><span class="p">,</span><span class="mf">0.03</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.03</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.03</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)]</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">Map_Linear</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tmp_data</span><span class="p">,</span><span class="s2">&quot;csc&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">tmp_attr</span><span class="p">),</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">model_id</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
            <span class="n">cv_parameter_set</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">Map_KNN</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tmp_data</span><span class="p">,</span><span class="s2">&quot;csc&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">tmp_attr</span><span class="p">),</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">model_id</span> <span class="o">==</span> <span class="mi">3</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">CBF_KNN</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tmp_data</span><span class="p">,</span><span class="s2">&quot;csc&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">tmp_attr</span><span class="p">),</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">model_id</span> <span class="o">==</span> <span class="mi">4</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">Map_Random</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">tmp_data</span><span class="p">,</span><span class="s2">&quot;csc&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">tmp_attr</span><span class="p">),</span> <span class="n">bpr_k</span><span class="p">,</span> <span class="n">bpr_args</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">model_id</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">para</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cross_validation</span><span class="p">(</span><span class="n">cv_iters</span><span class="p">,</span> <span class="n">cv_parameter_set</span><span class="p">,</span> <span class="n">cv_folds</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">set_parameter</span><span class="p">(</span><span class="n">para</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_iters</span><span class="p">)</span>

        <span class="n">prec</span><span class="p">,</span> <span class="n">auc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">datamats</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">attrmats</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test for fold&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="s2">&quot;: Prec@n =&quot;</span><span class="p">,</span><span class="n">prec</span><span class="p">,</span><span class="s2">&quot;auc =&quot;</span><span class="p">,</span><span class="n">auc</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;------------------------------------------------&quot;</span><span class="p">)</span>
        <span class="n">avg_prec</span> <span class="o">+=</span> <span class="n">prec</span>
        <span class="n">avg_auc</span> <span class="o">+=</span> <span class="n">auc</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;avg_prec = &quot;</span><span class="p">,</span> <span class="n">avg_prec</span><span class="o">/</span><span class="n">num_folds</span><span class="p">,</span> <span class="s2">&quot;, avg_auc = &quot;</span><span class="p">,</span> <span class="n">avg_auc</span><span class="o">/</span><span class="n">num_folds</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="runs">
<h2>Runs<a class="headerlink" href="#runs" title="Permalink to this headline">¶</a></h2>
<p>0=Map_BPR 1=Map_Linear 2=Map_KNN 3=CBF_KNN 4=Random</p>
<div class="section" id="random">
<h3>Random<a class="headerlink" href="#random" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">main</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test for fold 0 : Prec@n = 0.34 auc = 0.40187818662818664
------------------------------------------------
Test for fold 1 : Prec@n = 0.23000000000000004 auc = 0.36780595330595334
------------------------------------------------
Test for fold 2 : Prec@n = 0.19 auc = 0.30416527916527913
------------------------------------------------
avg_prec =  0.25333333333333335 , avg_auc =  0.35794980636647306
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="cbf-knn">
<h3>CBF-KNN<a class="headerlink" href="#cbf-knn" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">main</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test for fold 0 : Prec@n = 0.35000000000000003 auc = 0.6394615477115477
------------------------------------------------
Test for fold 1 : Prec@n = 0.31 auc = 0.488562382062382
------------------------------------------------
Test for fold 2 : Prec@n = 0.09 auc = 0.21145521145521146
------------------------------------------------
avg_prec =  0.25 , avg_auc =  0.4464930470763804
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### Map-KNN</span>
<span class="n">main</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validating parameter 1 .........
iteration 0: loss = 43.40243399091855
iteration 1: loss = 40.65759467250106
iteration 2: loss = 37.850404923721015
iteration 3: loss = 36.12252169933082
iteration 4: loss = 33.60884418137949
iteration 5: loss = 32.73648687535113
iteration 6: loss = 31.443470041655193
iteration 7: loss = 30.511488100610023
iteration 8: loss = 30.054597528818107
iteration 9: loss = 29.903831916431155
prec@5 of cross-validation fold 0 : 0.25000000000000006
iteration 0: loss = 64.4090728002564
iteration 1: loss = 58.06587235120557
iteration 2: loss = 52.93512649079631
iteration 3: loss = 49.65735295762282
iteration 4: loss = 47.145812876094396
iteration 5: loss = 45.80213683270445
iteration 6: loss = 44.4974831686896
iteration 7: loss = 42.77294614129626
iteration 8: loss = 41.60951943560116
iteration 9: loss = 41.17911214468912
prec@5 of cross-validation fold 1 : 0.25
iteration 0: loss = 61.32393802142997
iteration 1: loss = 56.61785171648897
iteration 2: loss = 52.01337289263955
iteration 3: loss = 50.149989595324946
iteration 4: loss = 48.1626596598943
iteration 5: loss = 46.175831599348356
iteration 6: loss = 45.35313989794629
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:179: RuntimeWarning: invalid value encountered in true_divide
/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:180: RuntimeWarning: invalid value encountered in double_scalars
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>iteration 7: loss = 44.19893913590752
iteration 8: loss = 42.53815374221108
iteration 9: loss = 41.39456742078118
prec@5 of cross-validation fold 2 : 0.13
Average score for parameter after cross-validation 1 : 0.21
Cross-validating parameter 2 .........
iteration 0: loss = 44.831161945616216
iteration 1: loss = 40.76142681723129
iteration 2: loss = 39.0730877640284
iteration 3: loss = 36.48856464903984
iteration 4: loss = 34.468941470569455
iteration 5: loss = 32.61980395526727
iteration 6: loss = 31.606291029008787
iteration 7: loss = 30.470414216872534
iteration 8: loss = 29.487360945399644
iteration 9: loss = 27.85419391874221
prec@5 of cross-validation fold 0 : 0.26000000000000006
iteration 0: loss = 52.79399853538475
iteration 1: loss = 50.58614178324535
iteration 2: loss = 47.15013968108587
iteration 3: loss = 45.11858772907325
iteration 4: loss = 43.69562158794619
iteration 5: loss = 41.78073842155967
iteration 6: loss = 41.17133662772308
iteration 7: loss = 40.22444138018134
iteration 8: loss = 39.39257220458339
iteration 9: loss = 38.74770298171789
prec@5 of cross-validation fold 1 : 0.24000000000000005
iteration 0: loss = 56.346433575937795
iteration 1: loss = 52.28143558983291
iteration 2: loss = 48.63636639594341
iteration 3: loss = 46.78291956078614
iteration 4: loss = 44.292107183634776
iteration 5: loss = 41.78893820037616
iteration 6: loss = 40.152258484880655
iteration 7: loss = 38.9296484057496
iteration 8: loss = 37.80315576828086
iteration 9: loss = 36.992514456492174
prec@5 of cross-validation fold 2 : 0.13
Average score for parameter after cross-validation 2 : 0.21000000000000005
Cross-validating parameter 3 .........
iteration 0: loss = 35.08606491871245
iteration 1: loss = 33.53375153264883
iteration 2: loss = 32.13683535520916
iteration 3: loss = 31.238961397099658
iteration 4: loss = 30.5093403418766
iteration 5: loss = 29.784285929856797
iteration 6: loss = 29.511655007155007
iteration 7: loss = 28.94868001394659
iteration 8: loss = 28.4832194915134
iteration 9: loss = 27.943911475551985
prec@5 of cross-validation fold 0 : 0.26000000000000006
iteration 0: loss = 63.00610293308826
iteration 1: loss = 58.57886968697898
iteration 2: loss = 54.78304878688647
iteration 3: loss = 50.03941576682113
iteration 4: loss = 47.67348587289633
iteration 5: loss = 46.66131226105141
iteration 6: loss = 45.19878393819917
iteration 7: loss = 44.1126159468976
iteration 8: loss = 43.54142545797538
iteration 9: loss = 42.58062603592771
prec@5 of cross-validation fold 1 : 0.19000000000000003
iteration 0: loss = 65.06556784808845
iteration 1: loss = 56.37143403985609
iteration 2: loss = 53.08521079797845
iteration 3: loss = 50.27713249694848
iteration 4: loss = 48.40616553901774
iteration 5: loss = 46.9170325324579
iteration 6: loss = 45.22266961454842
iteration 7: loss = 43.392937023791205
iteration 8: loss = 42.51358269499687
iteration 9: loss = 41.88145551535415
prec@5 of cross-validation fold 2 : 0.15000000000000002
Average score for parameter after cross-validation 3 : 0.20000000000000004
best parameter in cross-validation : 2 with prec@n 0.21000000000000005
iteration 0: loss = 76.28673050930851
iteration 1: loss = 71.79427009403891
iteration 2: loss = 68.1584280968783
iteration 3: loss = 64.71021126203388
iteration 4: loss = 63.11561027200814
iteration 5: loss = 61.25679438117817
iteration 6: loss = 60.28227779319883
iteration 7: loss = 59.294960576796
iteration 8: loss = 58.51690654092427
iteration 9: loss = 57.93410776026923
iteration 10: loss = 57.1846746345047
iteration 11: loss = 55.91769486204663
iteration 12: loss = 55.42639933530113
iteration 13: loss = 54.6548447807004
iteration 14: loss = 54.724936065364254
iteration 15: loss = 53.9947598276371
iteration 16: loss = 53.51816000869425
iteration 17: loss = 52.75552264148136
iteration 18: loss = 52.395071495498904
iteration 19: loss = 51.827473093100636
Test for fold 0 : Prec@n = 0.3400000000000001 auc = 0.5143437673437674
------------------------------------------------
Cross-validating parameter 1 .........
iteration 0: loss = 53.1869316873635
iteration 1: loss = 49.23851190761488
iteration 2: loss = 46.31372372104262
iteration 3: loss = 44.25543412927418
iteration 4: loss = 43.06133728470088
iteration 5: loss = 41.93277870665634
iteration 6: loss = 40.92955472378242
iteration 7: loss = 40.39492651343292
iteration 8: loss = 39.492956853698345
iteration 9: loss = 38.57219163628457
prec@5 of cross-validation fold 0 : 0.3
iteration 0: loss = 81.76170922411431
iteration 1: loss = 74.29579759203912
iteration 2: loss = 68.46000854141361
iteration 3: loss = 64.80868277697506
iteration 4: loss = 62.649285879263374
iteration 5: loss = 59.72468065230031
iteration 6: loss = 58.18754161499027
iteration 7: loss = 56.96415596743242
iteration 8: loss = 55.081459740080774
iteration 9: loss = 53.808238834856205
prec@5 of cross-validation fold 1 : 0.2
iteration 0: loss = 115.93679071972426
iteration 1: loss = 103.7633962497899
iteration 2: loss = 95.47639622604781
iteration 3: loss = 86.53758702826957
iteration 4: loss = 81.92741075977989
iteration 5: loss = 78.94810330502568
iteration 6: loss = 76.43250546423978
iteration 7: loss = 74.8212550578003
iteration 8: loss = 72.59446220407688
iteration 9: loss = 71.16897361285532
prec@5 of cross-validation fold 2 : 0.13
Average score for parameter after cross-validation 1 : 0.21
Cross-validating parameter 2 .........
iteration 0: loss = 68.72292464512692
iteration 1: loss = 60.525547356162114
iteration 2: loss = 56.53771982996667
iteration 3: loss = 53.90520938631746
iteration 4: loss = 50.880296712870376
iteration 5: loss = 48.720816949949906
iteration 6: loss = 47.44042138848758
iteration 7: loss = 46.49834108976505
iteration 8: loss = 45.59541357051351
iteration 9: loss = 44.53717768389533
prec@5 of cross-validation fold 0 : 0.22000000000000003
iteration 0: loss = 76.93440737663748
iteration 1: loss = 68.02306956181035
iteration 2: loss = 61.41435511488804
iteration 3: loss = 57.33100427726546
iteration 4: loss = 54.88796220312288
iteration 5: loss = 52.68597860870178
iteration 6: loss = 51.31875930932274
iteration 7: loss = 49.96392689149043
iteration 8: loss = 48.75891385607049
iteration 9: loss = 47.24327727570021
prec@5 of cross-validation fold 1 : 0.25000000000000006
iteration 0: loss = 107.64578192473252
iteration 1: loss = 96.81972020955993
iteration 2: loss = 91.36887435332743
iteration 3: loss = 86.94697501271173
iteration 4: loss = 82.29293556517806
iteration 5: loss = 78.2824425576034
iteration 6: loss = 75.06456566319066
iteration 7: loss = 73.44841768183309
iteration 8: loss = 72.68415334091212
iteration 9: loss = 71.79855617178683
prec@5 of cross-validation fold 2 : 0.17
Average score for parameter after cross-validation 2 : 0.21333333333333337
Cross-validating parameter 3 .........
iteration 0: loss = 81.45870717349669
iteration 1: loss = 74.89283417369069
iteration 2: loss = 70.39084559612736
iteration 3: loss = 67.46362511561139
iteration 4: loss = 64.78326377613058
iteration 5: loss = 62.635625127621765
iteration 6: loss = 60.98400973356874
iteration 7: loss = 59.39501004573002
iteration 8: loss = 59.07542760046221
iteration 9: loss = 57.68533326754971
prec@5 of cross-validation fold 0 : 0.36999999999999994
iteration 0: loss = 83.05586548370444
iteration 1: loss = 72.09296277226142
iteration 2: loss = 66.09362613566503
iteration 3: loss = 62.290011169160834
iteration 4: loss = 59.313460893973314
iteration 5: loss = 57.09611005512291
iteration 6: loss = 55.65619669267673
iteration 7: loss = 54.870444910538936
iteration 8: loss = 53.370890247854376
iteration 9: loss = 52.1412714588534
prec@5 of cross-validation fold 1 : 0.28
iteration 0: loss = 110.95755245029903
iteration 1: loss = 99.3417491920096
iteration 2: loss = 91.26108824122758
iteration 3: loss = 85.8369997424384
iteration 4: loss = 81.80931363444697
iteration 5: loss = 77.71378591089723
iteration 6: loss = 76.06446429359609
iteration 7: loss = 74.91227934398228
iteration 8: loss = 73.07811889483177
iteration 9: loss = 71.16155571135889
prec@5 of cross-validation fold 2 : 0.15000000000000002
Average score for parameter after cross-validation 3 : 0.26666666666666666
best parameter in cross-validation : 3 with prec@n 0.26666666666666666
iteration 0: loss = 138.77809051226328
iteration 1: loss = 125.35669025089234
iteration 2: loss = 115.57909982801235
iteration 3: loss = 108.0344590801985
iteration 4: loss = 103.07675352893446
iteration 5: loss = 99.10910350678938
iteration 6: loss = 95.48334171516208
iteration 7: loss = 92.5740461420919
iteration 8: loss = 90.2979477648368
iteration 9: loss = 88.74560689712484
iteration 10: loss = 87.25517291442704
iteration 11: loss = 85.80724141588591
iteration 12: loss = 83.45082114893013
iteration 13: loss = 81.7330257133095
iteration 14: loss = 80.66432666162476
iteration 15: loss = 79.46130977578039
iteration 16: loss = 78.39700747068824
iteration 17: loss = 77.26577135237758
iteration 18: loss = 76.59235752832262
iteration 19: loss = 75.8085169423163
Test for fold 1 : Prec@n = 0.2 auc = 0.29203337403337404
------------------------------------------------
Cross-validating parameter 1 .........
iteration 0: loss = 90.20856764265909
iteration 1: loss = 81.67880037744551
iteration 2: loss = 76.51544384793665
iteration 3: loss = 72.66795025893701
iteration 4: loss = 69.9552351856739
iteration 5: loss = 68.74826463463579
iteration 6: loss = 66.72227331064357
iteration 7: loss = 64.45941960342373
iteration 8: loss = 63.368305863491464
iteration 9: loss = 63.109509704499224
prec@5 of cross-validation fold 0 : 0.28
iteration 0: loss = 112.72906093959065
iteration 1: loss = 99.37396952951198
iteration 2: loss = 92.94382012908636
iteration 3: loss = 88.06580882374006
iteration 4: loss = 83.98596082914884
iteration 5: loss = 80.41885598900058
iteration 6: loss = 78.66904968916904
iteration 7: loss = 75.99111968003011
iteration 8: loss = 74.64702385796856
iteration 9: loss = 72.09565490285922
prec@5 of cross-validation fold 1 : 0.37
iteration 0: loss = 105.96570925834638
iteration 1: loss = 96.59259614124058
iteration 2: loss = 88.29821603922298
iteration 3: loss = 83.05141643387675
iteration 4: loss = 80.50207043943675
iteration 5: loss = 79.14850783201992
iteration 6: loss = 76.36661234893717
iteration 7: loss = 74.28220239233181
iteration 8: loss = 72.74345360570766
iteration 9: loss = 71.39849995496321
prec@5 of cross-validation fold 2 : 0.32
Average score for parameter after cross-validation 1 : 0.3233333333333333
Cross-validating parameter 2 .........
iteration 0: loss = 105.34181908138254
iteration 1: loss = 92.42763262364716
iteration 2: loss = 83.8010763826438
iteration 3: loss = 78.7058238889885
iteration 4: loss = 73.2766838034653
iteration 5: loss = 69.38747424939623
iteration 6: loss = 66.19064411037434
iteration 7: loss = 63.56895929879138
iteration 8: loss = 62.477313698758515
iteration 9: loss = 61.765935377059236
prec@5 of cross-validation fold 0 : 0.26000000000000006
iteration 0: loss = 88.00582062319651
iteration 1: loss = 82.0114419355074
iteration 2: loss = 75.67875856816329
iteration 3: loss = 71.75985089440768
iteration 4: loss = 70.08130693646346
iteration 5: loss = 68.62867741707264
iteration 6: loss = 67.22791572139812
iteration 7: loss = 66.47133275001391
iteration 8: loss = 65.87442590701434
iteration 9: loss = 64.54610968898835
prec@5 of cross-validation fold 1 : 0.32
iteration 0: loss = 98.99405146612001
iteration 1: loss = 90.5827707900088
iteration 2: loss = 85.72184292530181
iteration 3: loss = 83.68908848717058
iteration 4: loss = 78.43651218663008
iteration 5: loss = 74.92447264826828
iteration 6: loss = 71.6064611442016
iteration 7: loss = 69.12427068466948
iteration 8: loss = 67.81967123422392
iteration 9: loss = 66.75509761113452
prec@5 of cross-validation fold 2 : 0.31
Average score for parameter after cross-validation 2 : 0.2966666666666667
Cross-validating parameter 3 .........
iteration 0: loss = 88.64842146181579
iteration 1: loss = 78.78838995152881
iteration 2: loss = 74.42113047194815
iteration 3: loss = 71.56282744550751
iteration 4: loss = 68.90470851684023
iteration 5: loss = 65.96255822028886
iteration 6: loss = 64.37810155239987
iteration 7: loss = 62.60544142686069
iteration 8: loss = 61.64523085096974
iteration 9: loss = 60.29229702274347
prec@5 of cross-validation fold 0 : 0.24000000000000007
iteration 0: loss = 116.31531039795414
iteration 1: loss = 99.70385966223014
iteration 2: loss = 90.75414256016089
iteration 3: loss = 85.31945746703403
iteration 4: loss = 81.12280731643224
iteration 5: loss = 78.52984715398168
iteration 6: loss = 76.83015563263936
iteration 7: loss = 75.71972317649926
iteration 8: loss = 75.29933499851016
iteration 9: loss = 73.03432836259424
prec@5 of cross-validation fold 1 : 0.3
iteration 0: loss = 109.91181895013813
iteration 1: loss = 102.03774030464812
iteration 2: loss = 98.41953623798821
iteration 3: loss = 93.5266811950956
iteration 4: loss = 91.15261313188493
iteration 5: loss = 89.31741898785431
iteration 6: loss = 86.6664531243207
iteration 7: loss = 86.10276421150806
iteration 8: loss = 83.27373563116922
iteration 9: loss = 81.7329905401836
prec@5 of cross-validation fold 2 : 0.24000000000000005
Average score for parameter after cross-validation 3 : 0.26
best parameter in cross-validation : 1 with prec@n 0.3233333333333333
iteration 0: loss = 155.75605511569893
iteration 1: loss = 143.82460279272107
iteration 2: loss = 132.88492774991477
iteration 3: loss = 124.90310473477817
iteration 4: loss = 120.45914214283623
iteration 5: loss = 118.78708726295352
iteration 6: loss = 114.28244333120517
iteration 7: loss = 112.72518274232357
iteration 8: loss = 110.78474359228113
iteration 9: loss = 106.81732173412004
iteration 10: loss = 104.17304361031096
iteration 11: loss = 102.47071052657381
iteration 12: loss = 99.73135540929007
iteration 13: loss = 98.58665323471672
iteration 14: loss = 97.775835251675
iteration 15: loss = 95.74445276370975
iteration 16: loss = 93.9317302257866
iteration 17: loss = 94.36916192307723
iteration 18: loss = 91.94268848566844
iteration 19: loss = 90.66369526349945
Test for fold 2 : Prec@n = 0.13999999999999999 auc = 0.16775863025863025
------------------------------------------------
avg_prec =  0.22666666666666668 , avg_auc =  0.32471192387859055
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### Map-Linear</span>
<span class="n">main</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validating parameter (0.03, 0.03) .........
iteration 0: loss = 38.72110191953468
iteration 1: loss = 37.33848327162904
iteration 2: loss = 35.852620509390334
iteration 3: loss = 34.36757973583349
iteration 4: loss = 32.75507774618757
iteration 5: loss = 31.803825179188497
iteration 6: loss = 31.30625507899908
iteration 7: loss = 30.522994369260182
iteration 8: loss = 30.055099726478865
iteration 9: loss = 29.145269779842653
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.24000000000000005
iteration 0: loss = 63.75652757049426
iteration 1: loss = 59.71755507985954
iteration 2: loss = 54.57610556646238
iteration 3: loss = 52.19316147481439
iteration 4: loss = 50.550792544725056
iteration 5: loss = 48.46283508764442
iteration 6: loss = 47.18710443195921
iteration 7: loss = 45.63929716811934
iteration 8: loss = 44.70338869295071
iteration 9: loss = 43.70523819724141
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.21000000000000002
iteration 0: loss = 50.44807258184729
iteration 1: loss = 47.03861752127486
iteration 2: loss = 45.831738932562125
iteration 3: loss = 44.44770320376346
iteration 4: loss = 43.47216498160616
iteration 5: loss = 42.11015258504228
iteration 6: loss = 41.7422444910796
iteration 7: loss = 40.86066882699268
iteration 8: loss = 40.66017935827529
iteration 9: loss = 40.330093107992106
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.14000000000000004
Average score for parameter after cross-validation (0.03, 0.03) : 0.19666666666666668
Cross-validating parameter (0.03, 0.1) .........
iteration 0: loss = 44.51203969251187
iteration 1: loss = 42.35983720180233
iteration 2: loss = 41.24991151374239
iteration 3: loss = 39.87535180437539
iteration 4: loss = 38.4123794989418
iteration 5: loss = 36.937801579142295
iteration 6: loss = 35.34631999637787
iteration 7: loss = 34.850258560777185
iteration 8: loss = 34.387713088803935
iteration 9: loss = 33.866926700041375
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.24000000000000005
iteration 0: loss = 52.35650538406176
iteration 1: loss = 49.08081134489775
iteration 2: loss = 47.22220182664272
iteration 3: loss = 45.89629892166444
iteration 4: loss = 44.368985950261774
iteration 5: loss = 43.56503230063383
iteration 6: loss = 42.85996122828686
iteration 7: loss = 41.84549297182073
iteration 8: loss = 41.24527274350195
iteration 9: loss = 40.84569275443251
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.21000000000000002
iteration 0: loss = 58.022518493619664
iteration 1: loss = 56.07603633081405
iteration 2: loss = 53.01054502673558
iteration 3: loss = 51.041153599388366
iteration 4: loss = 50.055067526299496
iteration 5: loss = 48.726283997252224
iteration 6: loss = 48.42671340967409
iteration 7: loss = 47.47039188539853
iteration 8: loss = 46.03137923895811
iteration 9: loss = 45.114571734376426
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.14000000000000004
Average score for parameter after cross-validation (0.03, 0.1) : 0.19666666666666668
Cross-validating parameter (0.1, 0.03) .........
iteration 0: loss = 35.38839472709905
iteration 1: loss = 33.44711625579536
iteration 2: loss = 31.42770217291145
iteration 3: loss = 30.44107633196943
iteration 4: loss = 29.343255355031754
iteration 5: loss = 27.722410703240723
iteration 6: loss = 26.519678105585577
iteration 7: loss = 25.62289652243623
iteration 8: loss = 24.84586262168021
iteration 9: loss = 23.8575693454898
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.24000000000000005
iteration 0: loss = 58.50199265867212
iteration 1: loss = 53.83356663667264
iteration 2: loss = 51.0642565124257
iteration 3: loss = 48.736185000902836
iteration 4: loss = 47.392721909214636
iteration 5: loss = 45.87478964631016
iteration 6: loss = 44.64390651148578
iteration 7: loss = 44.115585739623114
iteration 8: loss = 43.671152453708245
iteration 9: loss = 43.25171667129495
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.21000000000000002
iteration 0: loss = 74.04799308483484
iteration 1: loss = 68.92629327472721
iteration 2: loss = 65.04668115071402
iteration 3: loss = 61.77180553124112
iteration 4: loss = 59.11730614161611
iteration 5: loss = 56.10266654823612
iteration 6: loss = 53.69817344332952
iteration 7: loss = 52.68986299445123
iteration 8: loss = 50.72871387749008
iteration 9: loss = 49.159301463890316
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.13
Average score for parameter after cross-validation (0.1, 0.03) : 0.19333333333333336
Cross-validating parameter (0.1, 0.1) .........
iteration 0: loss = 38.226564678770174
iteration 1: loss = 35.88599717985704
iteration 2: loss = 32.67278659099904
iteration 3: loss = 30.63455667228466
iteration 4: loss = 29.56763771833808
iteration 5: loss = 28.251761015607983
iteration 6: loss = 26.818618987622532
iteration 7: loss = 26.06090631668346
iteration 8: loss = 25.125574927622345
iteration 9: loss = 24.68277483569384
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.24000000000000005
iteration 0: loss = 50.33263946057157
iteration 1: loss = 47.976382388010784
iteration 2: loss = 45.51497587592171
iteration 3: loss = 45.777318046615314
iteration 4: loss = 44.10622602961264
iteration 5: loss = 42.95162922950871
iteration 6: loss = 42.72338423114154
iteration 7: loss = 42.1556385088286
iteration 8: loss = 41.581172832826994
iteration 9: loss = 41.211010304137204
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.21000000000000002
iteration 0: loss = 60.05377272926742
iteration 1: loss = 56.4428499267014
iteration 2: loss = 51.23189501057954
iteration 3: loss = 48.44568610847839
iteration 4: loss = 47.59736122313833
iteration 5: loss = 46.17529873689218
iteration 6: loss = 44.77404987085256
iteration 7: loss = 43.966564038897474
iteration 8: loss = 43.7310603579124
iteration 9: loss = 42.76591429016679
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.13
Average score for parameter after cross-validation (0.1, 0.1) : 0.19333333333333336
best parameter in cross-validation : (0.03, 0.03) with prec@n 0.19666666666666668
iteration 0: loss = 78.71908367324262
iteration 1: loss = 73.80289816209095
iteration 2: loss = 70.16309293308794
iteration 3: loss = 66.0784267448405
iteration 4: loss = 63.56276664841539
iteration 5: loss = 62.30246287636227
iteration 6: loss = 60.949353186099984
iteration 7: loss = 58.98521273308824
iteration 8: loss = 57.83051938468452
iteration 9: loss = 56.42111018002737
iteration 10: loss = 55.919820170927494
iteration 11: loss = 54.45270769440145
iteration 12: loss = 52.9084908266318
iteration 13: loss = 51.833315234265186
iteration 14: loss = 51.58881112746023
iteration 15: loss = 50.552064712711854
iteration 16: loss = 49.56145798819622
iteration 17: loss = 49.62983425687048
iteration 18: loss = 48.62940586541692
iteration 19: loss = 48.17589839128594
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
Mapper Map_Linear trainning for iteration 10 ...
Mapper Map_Linear trainning for iteration 11 ...
Mapper Map_Linear trainning for iteration 12 ...
Mapper Map_Linear trainning for iteration 13 ...
Mapper Map_Linear trainning for iteration 14 ...
Mapper Map_Linear trainning for iteration 15 ...
Mapper Map_Linear trainning for iteration 16 ...
Mapper Map_Linear trainning for iteration 17 ...
Mapper Map_Linear trainning for iteration 18 ...
Mapper Map_Linear trainning for iteration 19 ...
Test for fold 0 : Prec@n = 0.38 auc = 0.5291151163651163
------------------------------------------------
Cross-validating parameter (0.03, 0.03) .........
iteration 0: loss = 75.85577432372551
iteration 1: loss = 70.53425915121724
iteration 2: loss = 65.6175367899295
iteration 3: loss = 62.94848718526701
iteration 4: loss = 60.54025371784861
iteration 5: loss = 58.92922062751449
iteration 6: loss = 57.63486469513007
iteration 7: loss = 56.54646352175845
iteration 8: loss = 55.66639048409365
iteration 9: loss = 54.80039701558939
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.32
iteration 0: loss = 71.5953991719417
iteration 1: loss = 66.20778540244862
iteration 2: loss = 61.521543313095066
iteration 3: loss = 59.84308851048047
iteration 4: loss = 56.62964299068872
iteration 5: loss = 54.20637780054307
iteration 6: loss = 53.46722179686061
iteration 7: loss = 50.961694186313274
iteration 8: loss = 49.3893453250318
iteration 9: loss = 48.52183614136226
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.22000000000000003
iteration 0: loss = 106.12330352434272
iteration 1: loss = 93.96527064923454
iteration 2: loss = 85.60393247568958
iteration 3: loss = 81.63847539709238
iteration 4: loss = 77.85311124407627
iteration 5: loss = 75.94269420459804
iteration 6: loss = 73.78128058443149
iteration 7: loss = 71.60434595311051
iteration 8: loss = 70.62708064128518
iteration 9: loss = 69.09422669521165
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.14
Average score for parameter after cross-validation (0.03, 0.03) : 0.22666666666666668
Cross-validating parameter (0.03, 0.1) .........
iteration 0: loss = 61.56966895344209
iteration 1: loss = 55.420406712037156
iteration 2: loss = 51.58858521345395
iteration 3: loss = 49.817370580590634
iteration 4: loss = 47.170903317212755
iteration 5: loss = 45.15905241507549
iteration 6: loss = 44.380434484851214
iteration 7: loss = 43.33365901135963
iteration 8: loss = 42.78718572527674
iteration 9: loss = 41.98920434894307
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.32
iteration 0: loss = 51.80164975226287
iteration 1: loss = 50.37112128380707
iteration 2: loss = 49.42128921346582
iteration 3: loss = 48.08370459117578
iteration 4: loss = 46.624485436696176
iteration 5: loss = 46.08796712598863
iteration 6: loss = 45.19669589078613
iteration 7: loss = 44.63931585883654
iteration 8: loss = 43.728088741146124
iteration 9: loss = 43.557207550250965
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.17
iteration 0: loss = 110.12192849239005
iteration 1: loss = 100.75608815967121
iteration 2: loss = 94.50049377074673
iteration 3: loss = 89.23566480123391
iteration 4: loss = 85.60274596276054
iteration 5: loss = 81.57123868357002
iteration 6: loss = 79.08016404817818
iteration 7: loss = 77.07868094426391
iteration 8: loss = 75.02330896430117
iteration 9: loss = 73.16075075927311
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.14
Average score for parameter after cross-validation (0.03, 0.1) : 0.21
Cross-validating parameter (0.1, 0.03) .........
iteration 0: loss = 67.34267083761549
iteration 1: loss = 61.09113180221871
iteration 2: loss = 57.36250784380786
iteration 3: loss = 54.233973049026076
iteration 4: loss = 52.61631025843409
iteration 5: loss = 50.385304710047194
iteration 6: loss = 49.25325462504185
iteration 7: loss = 48.10534278855641
iteration 8: loss = 46.66963416644785
iteration 9: loss = 45.64129170436033
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.32
iteration 0: loss = 89.3893670509352
iteration 1: loss = 78.39871450776607
iteration 2: loss = 71.74684598265837
iteration 3: loss = 66.85218792167939
iteration 4: loss = 62.325573443710255
iteration 5: loss = 59.675333287440516
iteration 6: loss = 57.92130702894602
iteration 7: loss = 55.95546468034375
iteration 8: loss = 54.97575145784492
iteration 9: loss = 54.13562026166726
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.26
iteration 0: loss = 96.94851233046954
iteration 1: loss = 86.79389243215282
iteration 2: loss = 80.26606742641434
iteration 3: loss = 76.27940400973092
iteration 4: loss = 72.95981572047938
iteration 5: loss = 69.8899050525978
iteration 6: loss = 67.82523585517136
iteration 7: loss = 65.83519891472497
iteration 8: loss = 64.18761430175375
iteration 9: loss = 62.82341657812361
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.14000000000000004
Average score for parameter after cross-validation (0.1, 0.03) : 0.24000000000000002
Cross-validating parameter (0.1, 0.1) .........
iteration 0: loss = 76.87293798953588
iteration 1: loss = 71.46300337331505
iteration 2: loss = 66.97374030529856
iteration 3: loss = 63.54310864928047
iteration 4: loss = 58.90326149109913
iteration 5: loss = 56.626285350087336
iteration 6: loss = 54.44027540735155
iteration 7: loss = 52.6555113228943
iteration 8: loss = 51.32767623349268
iteration 9: loss = 50.029286071708015
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.32
iteration 0: loss = 84.86049932192518
iteration 1: loss = 70.83708270625695
iteration 2: loss = 62.02053099287983
iteration 3: loss = 56.533578558907344
iteration 4: loss = 53.5846849346443
iteration 5: loss = 50.81302190480561
iteration 6: loss = 49.17038138698103
iteration 7: loss = 46.51317148039881
iteration 8: loss = 45.68479826634973
iteration 9: loss = 44.64725029652452
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.18
iteration 0: loss = 114.85121471018834
iteration 1: loss = 102.96901378542532
iteration 2: loss = 96.17080201859324
iteration 3: loss = 91.08695075787969
iteration 4: loss = 86.61886129263384
iteration 5: loss = 82.51275008669731
iteration 6: loss = 79.54434714053663
iteration 7: loss = 77.7289413983446
iteration 8: loss = 76.27798830345117
iteration 9: loss = 75.3185637906642
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.15000000000000002
Average score for parameter after cross-validation (0.1, 0.1) : 0.21666666666666667
best parameter in cross-validation : (0.1, 0.03) with prec@n 0.24000000000000002
iteration 0: loss = 124.46006628607819
iteration 1: loss = 112.36033012184456
iteration 2: loss = 107.38807287902765
iteration 3: loss = 103.27960696659312
iteration 4: loss = 98.86547295951968
iteration 5: loss = 96.76355982144976
iteration 6: loss = 94.94849916580031
iteration 7: loss = 92.54673235236027
iteration 8: loss = 90.06550044959505
iteration 9: loss = 88.32668486762023
iteration 10: loss = 88.66233493841327
iteration 11: loss = 88.43834118231393
iteration 12: loss = 87.08089352447443
iteration 13: loss = 86.6343984233306
iteration 14: loss = 85.45103083853346
iteration 15: loss = 84.56132057182904
iteration 16: loss = 83.79341944177965
iteration 17: loss = 83.03166695501167
iteration 18: loss = 81.24723740599796
iteration 19: loss = 80.11479767990198
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
Mapper Map_Linear trainning for iteration 10 ...
Mapper Map_Linear trainning for iteration 11 ...
Mapper Map_Linear trainning for iteration 12 ...
Mapper Map_Linear trainning for iteration 13 ...
Mapper Map_Linear trainning for iteration 14 ...
Mapper Map_Linear trainning for iteration 15 ...
Mapper Map_Linear trainning for iteration 16 ...
Mapper Map_Linear trainning for iteration 17 ...
Mapper Map_Linear trainning for iteration 18 ...
Mapper Map_Linear trainning for iteration 19 ...
Test for fold 1 : Prec@n = 0.2700000000000001 auc = 0.4208597698597698
------------------------------------------------
Cross-validating parameter (0.03, 0.03) .........
iteration 0: loss = 95.34204233411499
iteration 1: loss = 87.25362311158572
iteration 2: loss = 79.86558109838077
iteration 3: loss = 76.56375360582524
iteration 4: loss = 74.37286565679707
iteration 5: loss = 72.73522351858287
iteration 6: loss = 71.07676538623056
iteration 7: loss = 69.63816927384937
iteration 8: loss = 69.04064127944392
iteration 9: loss = 67.55186709844355
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.32
iteration 0: loss = 101.49658886372552
iteration 1: loss = 92.29456620243754
iteration 2: loss = 86.19342668032513
iteration 3: loss = 81.20117229494916
iteration 4: loss = 77.3471826414692
iteration 5: loss = 74.56633860858292
iteration 6: loss = 73.18638222696231
iteration 7: loss = 70.25710807841352
iteration 8: loss = 69.07630175347363
iteration 9: loss = 68.94704819831247
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.26000000000000006
iteration 0: loss = 101.83879418832473
iteration 1: loss = 94.57437199776861
iteration 2: loss = 87.50326290443226
iteration 3: loss = 83.36251561228214
iteration 4: loss = 81.70253197221848
iteration 5: loss = 79.13341890876865
iteration 6: loss = 77.30777697260399
iteration 7: loss = 75.46961298426702
iteration 8: loss = 74.62493573502663
iteration 9: loss = 72.7745518752809
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.3200000000000001
Average score for parameter after cross-validation (0.03, 0.03) : 0.30000000000000004
Cross-validating parameter (0.03, 0.1) .........
iteration 0: loss = 100.96297257438103
iteration 1: loss = 93.50955403874838
iteration 2: loss = 85.87860777547444
iteration 3: loss = 79.1017167477718
iteration 4: loss = 75.61447085083407
iteration 5: loss = 72.78051724482998
iteration 6: loss = 70.89973701773035
iteration 7: loss = 69.61236969390718
iteration 8: loss = 67.63375044538509
iteration 9: loss = 66.5265372847443
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.32
iteration 0: loss = 99.36169910689968
iteration 1: loss = 93.9240540449201
iteration 2: loss = 86.45749199528045
iteration 3: loss = 81.93041776058466
iteration 4: loss = 77.87274604507624
iteration 5: loss = 75.39207444067705
iteration 6: loss = 73.59235182561844
iteration 7: loss = 72.16618707243057
iteration 8: loss = 70.95295397970035
iteration 9: loss = 69.87080505195053
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.23000000000000004
iteration 0: loss = 103.13612121726243
iteration 1: loss = 94.36486876319391
iteration 2: loss = 87.8909129253078
iteration 3: loss = 83.99277477706907
iteration 4: loss = 80.97948169458431
iteration 5: loss = 78.50708338346094
iteration 6: loss = 76.61789257301174
iteration 7: loss = 75.64240440779338
iteration 8: loss = 73.85526681444277
iteration 9: loss = 72.69186544616582
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.3200000000000001
Average score for parameter after cross-validation (0.03, 0.1) : 0.29000000000000004
Cross-validating parameter (0.1, 0.03) .........
iteration 0: loss = 94.08119232891474
iteration 1: loss = 85.84226377416495
iteration 2: loss = 77.13570413856304
iteration 3: loss = 73.53034379845093
iteration 4: loss = 70.65253550644454
iteration 5: loss = 67.4571580133078
iteration 6: loss = 66.43142980058005
iteration 7: loss = 64.17251777978879
iteration 8: loss = 63.42628189334437
iteration 9: loss = 62.21524908141399
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.33
iteration 0: loss = 106.18650206946616
iteration 1: loss = 98.9380644853544
iteration 2: loss = 91.38940046338669
iteration 3: loss = 86.19887636806399
iteration 4: loss = 81.36374968320874
iteration 5: loss = 78.52743901550392
iteration 6: loss = 75.83783940116957
iteration 7: loss = 73.0848124251452
iteration 8: loss = 71.22656588394358
iteration 9: loss = 69.34866441843226
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.2700000000000001
iteration 0: loss = 89.19192174443849
iteration 1: loss = 82.25161729736494
iteration 2: loss = 79.53980462112716
iteration 3: loss = 75.7859445229158
iteration 4: loss = 73.09621558933762
iteration 5: loss = 70.62608642255864
iteration 6: loss = 68.82008650129762
iteration 7: loss = 66.5167431236496
iteration 8: loss = 65.06869572226736
iteration 9: loss = 63.53376673541463
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.3200000000000001
Average score for parameter after cross-validation (0.1, 0.03) : 0.3066666666666667
Cross-validating parameter (0.1, 0.1) .........
iteration 0: loss = 103.77810488017015
iteration 1: loss = 92.21332507051272
iteration 2: loss = 84.45588017260394
iteration 3: loss = 79.3637195216271
iteration 4: loss = 75.86235553095273
iteration 5: loss = 72.68646988310891
iteration 6: loss = 71.22059255042284
iteration 7: loss = 68.58036897253992
iteration 8: loss = 66.83775046600202
iteration 9: loss = 65.42670797270429
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.32
iteration 0: loss = 92.73810851430943
iteration 1: loss = 82.3396750726133
iteration 2: loss = 77.37436740213772
iteration 3: loss = 73.99576304579358
iteration 4: loss = 69.09108316394895
iteration 5: loss = 66.43836118417222
iteration 6: loss = 64.133735679214
iteration 7: loss = 61.805945651765924
iteration 8: loss = 60.070955753114205
iteration 9: loss = 58.08845186324167
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.23000000000000004
iteration 0: loss = 111.28785238955332
iteration 1: loss = 100.94018881801168
iteration 2: loss = 92.42932889155774
iteration 3: loss = 87.10087940234253
iteration 4: loss = 83.84903087935322
iteration 5: loss = 82.01921727514019
iteration 6: loss = 79.69171411894177
iteration 7: loss = 77.81022059671957
iteration 8: loss = 75.58763427874123
iteration 9: loss = 74.27966224065084
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.3200000000000001
Average score for parameter after cross-validation (0.1, 0.1) : 0.29000000000000004
best parameter in cross-validation : (0.1, 0.03) with prec@n 0.3066666666666667
iteration 0: loss = 171.11205397190705
iteration 1: loss = 149.99138263358213
iteration 2: loss = 136.85139418484243
iteration 3: loss = 127.50416778318433
iteration 4: loss = 120.38799013936473
iteration 5: loss = 113.81416094454435
iteration 6: loss = 109.9310828721341
iteration 7: loss = 106.22498070862731
iteration 8: loss = 103.45511543336255
iteration 9: loss = 100.85828495797978
iteration 10: loss = 97.51173073194963
iteration 11: loss = 94.81880027810881
iteration 12: loss = 92.85864620305833
iteration 13: loss = 90.57206310586213
iteration 14: loss = 88.91203936762143
iteration 15: loss = 87.65031086737943
iteration 16: loss = 85.7929225379281
iteration 17: loss = 84.59973723898746
iteration 18: loss = 83.15500726797657
iteration 19: loss = 82.78261495983034
Mapper Map_Linear trainning for iteration 0 ...
Mapper Map_Linear trainning for iteration 1 ...
Mapper Map_Linear trainning for iteration 2 ...
Mapper Map_Linear trainning for iteration 3 ...
Mapper Map_Linear trainning for iteration 4 ...
Mapper Map_Linear trainning for iteration 5 ...
Mapper Map_Linear trainning for iteration 6 ...
Mapper Map_Linear trainning for iteration 7 ...
Mapper Map_Linear trainning for iteration 8 ...
Mapper Map_Linear trainning for iteration 9 ...
Mapper Map_Linear trainning for iteration 10 ...
Mapper Map_Linear trainning for iteration 11 ...
Mapper Map_Linear trainning for iteration 12 ...
Mapper Map_Linear trainning for iteration 13 ...
Mapper Map_Linear trainning for iteration 14 ...
Mapper Map_Linear trainning for iteration 15 ...
Mapper Map_Linear trainning for iteration 16 ...
Mapper Map_Linear trainning for iteration 17 ...
Mapper Map_Linear trainning for iteration 18 ...
Mapper Map_Linear trainning for iteration 19 ...
Test for fold 2 : Prec@n = 0.15 auc = 0.2594079531579532
------------------------------------------------
avg_prec =  0.2666666666666667 , avg_auc =  0.40312761312761314
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### Map-BPR</span>
<span class="n">main</span><span class="p">(</span><span class="n">model_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validating parameter (0.03, 0.03) .........
iteration 0: loss = 29.977828699989207
iteration 1: loss = 29.34276911568471
iteration 2: loss = 28.46009811702563
iteration 3: loss = 27.861713108035186
iteration 4: loss = 27.145908463397376
iteration 5: loss = 26.111656378970473
iteration 6: loss = 25.81385972458753
iteration 7: loss = 25.030018575284664
iteration 8: loss = 24.56115325004894
iteration 9: loss = 24.50204897123986
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.22000000000000006
iteration 0: loss = 61.509460706919356
iteration 1: loss = 56.915374288454586
iteration 2: loss = 51.4337747816551
iteration 3: loss = 48.45501331624014
iteration 4: loss = 47.490596610295924
iteration 5: loss = 45.877182279668816
iteration 6: loss = 43.68084482673598
iteration 7: loss = 41.91725148187348
iteration 8: loss = 40.73373767190496
iteration 9: loss = 40.1416990005772
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.14
iteration 0: loss = 65.40703794998775
iteration 1: loss = 62.735088464148745
iteration 2: loss = 57.3689706870058
iteration 3: loss = 52.94686365335909
iteration 4: loss = 50.69818182525377
iteration 5: loss = 48.003042977951175
iteration 6: loss = 46.51843588206096
iteration 7: loss = 45.98412955919399
iteration 8: loss = 44.36576856618166
iteration 9: loss = 43.17019349097438
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.13
Average score for parameter after cross-validation (0.03, 0.03) : 0.16333333333333336
Cross-validating parameter (0.03, 0.1) .........
iteration 0: loss = 40.086073241475454
iteration 1: loss = 37.95153743034384
iteration 2: loss = 36.94721565893394
iteration 3: loss = 35.687513838090865
iteration 4: loss = 34.415498524897
iteration 5: loss = 33.730906237606206
iteration 6: loss = 33.54396391566418
iteration 7: loss = 32.51745535304978
iteration 8: loss = 31.659978474627362
iteration 9: loss = 30.73604259781784
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.30000000000000004
iteration 0: loss = 60.6652611709918
iteration 1: loss = 56.36742257623443
iteration 2: loss = 53.83268925868299
iteration 3: loss = 50.424245617685614
iteration 4: loss = 47.74112090742891
iteration 5: loss = 45.941029512045915
iteration 6: loss = 44.77726076449809
iteration 7: loss = 43.433642171398915
iteration 8: loss = 43.18354663186356
iteration 9: loss = 42.29566534273625
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.21000000000000005
iteration 0: loss = 64.48853694471995
iteration 1: loss = 59.21720897563975
iteration 2: loss = 55.97129342348772
iteration 3: loss = 54.01978939346952
iteration 4: loss = 52.07998884668258
iteration 5: loss = 51.09337878907781
iteration 6: loss = 50.2425742949512
iteration 7: loss = 49.512188691622455
iteration 8: loss = 48.100194755056485
iteration 9: loss = 47.56016706637163
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.19000000000000003
Average score for parameter after cross-validation (0.03, 0.1) : 0.2333333333333334
Cross-validating parameter (0.1, 0.03) .........
iteration 0: loss = 35.191383984304565
iteration 1: loss = 33.74530498333268
iteration 2: loss = 32.163308628076564
iteration 3: loss = 30.456497876747157
iteration 4: loss = 29.769366988786413
iteration 5: loss = 28.966158099237436
iteration 6: loss = 28.548899758905392
iteration 7: loss = 27.510649646458987
iteration 8: loss = 27.155669686775457
iteration 9: loss = 26.384102292447537
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.2700000000000001
iteration 0: loss = 64.45830451375328
iteration 1: loss = 57.596641376542074
iteration 2: loss = 52.48995725490479
iteration 3: loss = 49.41590345446434
iteration 4: loss = 46.32944634626301
iteration 5: loss = 43.731889504334774
iteration 6: loss = 42.62479960871868
iteration 7: loss = 40.74894460829719
iteration 8: loss = 39.47935697816516
iteration 9: loss = 38.408570144684234
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.22000000000000003
iteration 0: loss = 66.60807036394876
iteration 1: loss = 60.44360094114895
iteration 2: loss = 56.298128329635674
iteration 3: loss = 52.99477922049538
iteration 4: loss = 50.67080030078757
iteration 5: loss = 48.87896745811647
iteration 6: loss = 46.499258147769794
iteration 7: loss = 45.68182819929654
iteration 8: loss = 45.02491580651321
iteration 9: loss = 44.2406190531355
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.07999999999999999
Average score for parameter after cross-validation (0.1, 0.03) : 0.19000000000000003
Cross-validating parameter (0.1, 0.1) .........
iteration 0: loss = 49.50232070789762
iteration 1: loss = 46.64124555743094
iteration 2: loss = 43.54571662754808
iteration 3: loss = 39.79557958026745
iteration 4: loss = 38.33458797639979
iteration 5: loss = 36.38587557285952
iteration 6: loss = 35.23970827220485
iteration 7: loss = 33.79654809809035
iteration 8: loss = 32.24562977608936
iteration 9: loss = 30.877356864043843
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.30000000000000004
iteration 0: loss = 34.26557095053759
iteration 1: loss = 33.238287506594475
iteration 2: loss = 32.45542715966752
iteration 3: loss = 31.761312839729126
iteration 4: loss = 31.09584831797708
iteration 5: loss = 30.42309411647719
iteration 6: loss = 29.794170952988793
iteration 7: loss = 29.60748186278383
iteration 8: loss = 29.253953032908896
iteration 9: loss = 29.115276340243994
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.25
iteration 0: loss = 56.05096739519354
iteration 1: loss = 51.780888069270766
iteration 2: loss = 48.536815202202696
iteration 3: loss = 45.806521480357844
iteration 4: loss = 44.55378146249163
iteration 5: loss = 43.16817947409752
iteration 6: loss = 41.89461447767185
iteration 7: loss = 41.13713950622773
iteration 8: loss = 40.66797056252193
iteration 9: loss = 40.0955722643599
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.13
Average score for parameter after cross-validation (0.1, 0.1) : 0.22666666666666668
best parameter in cross-validation : (0.03, 0.1) with prec@n 0.2333333333333334
iteration 0: loss = 99.6919598878761
iteration 1: loss = 91.1093044849722
iteration 2: loss = 84.24359688753194
iteration 3: loss = 80.82750636084987
iteration 4: loss = 78.53894012781251
iteration 5: loss = 76.52748772090771
iteration 6: loss = 74.11553612952504
iteration 7: loss = 71.98936308181023
iteration 8: loss = 70.42397310991454
iteration 9: loss = 69.46960960568629
iteration 10: loss = 68.9956321070601
iteration 11: loss = 66.66601183854385
iteration 12: loss = 66.09219908558549
iteration 13: loss = 65.7109633174326
iteration 14: loss = 64.32498166609561
iteration 15: loss = 63.8802129563811
iteration 16: loss = 63.23908758815965
iteration 17: loss = 62.19339784272758
iteration 18: loss = 61.848605953670614
iteration 19: loss = 61.39592329968908
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
Mapper Map_BPR trainning for iteration 10 ...
Mapper Map_BPR trainning for iteration 11 ...
Mapper Map_BPR trainning for iteration 12 ...
Mapper Map_BPR trainning for iteration 13 ...
Mapper Map_BPR trainning for iteration 14 ...
Mapper Map_BPR trainning for iteration 15 ...
Mapper Map_BPR trainning for iteration 16 ...
Mapper Map_BPR trainning for iteration 17 ...
Mapper Map_BPR trainning for iteration 18 ...
Mapper Map_BPR trainning for iteration 19 ...
Test for fold 0 : Prec@n = 0.38 auc = 0.5001042753542754
------------------------------------------------
Cross-validating parameter (0.03, 0.03) .........
iteration 0: loss = 76.02032723683715
iteration 1: loss = 69.79198127087436
iteration 2: loss = 64.00661033040846
iteration 3: loss = 61.4111758697577
iteration 4: loss = 59.132526043625795
iteration 5: loss = 57.52146669549399
iteration 6: loss = 56.23855961592831
iteration 7: loss = 54.81353074824324
iteration 8: loss = 53.960922215524505
iteration 9: loss = 53.00359937459818
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.20000000000000004
iteration 0: loss = 77.15118515902054
iteration 1: loss = 71.07370636263673
iteration 2: loss = 64.95093296750602
iteration 3: loss = 59.74190184552493
iteration 4: loss = 56.93888942924824
iteration 5: loss = 53.80065096453046
iteration 6: loss = 51.78972064180289
iteration 7: loss = 49.77629246387353
iteration 8: loss = 48.13929066199729
iteration 9: loss = 46.67315620145511
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.22000000000000003
iteration 0: loss = 114.32446497478954
iteration 1: loss = 101.39826846650008
iteration 2: loss = 94.25682448832741
iteration 3: loss = 90.06730888744903
iteration 4: loss = 86.56652072242028
iteration 5: loss = 84.12828514895186
iteration 6: loss = 82.39940267380629
iteration 7: loss = 80.4785560596325
iteration 8: loss = 78.80278776050969
iteration 9: loss = 77.669915040804
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.15000000000000002
Average score for parameter after cross-validation (0.03, 0.03) : 0.19000000000000003
Cross-validating parameter (0.03, 0.1) .........
iteration 0: loss = 81.99556460200438
iteration 1: loss = 73.219466122013
iteration 2: loss = 65.74687172272183
iteration 3: loss = 61.62886306064817
iteration 4: loss = 59.19995640666398
iteration 5: loss = 56.955500639690044
iteration 6: loss = 55.596570137334695
iteration 7: loss = 54.59891966472628
iteration 8: loss = 54.086208903023234
iteration 9: loss = 53.38443401747381
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.41000000000000003
iteration 0: loss = 90.3694834294592
iteration 1: loss = 76.84762067743118
iteration 2: loss = 70.3667917202881
iteration 3: loss = 63.47469769407084
iteration 4: loss = 59.214564678413446
iteration 5: loss = 56.298832561566826
iteration 6: loss = 54.71979739136732
iteration 7: loss = 52.9314952509562
iteration 8: loss = 51.5601006138991
iteration 9: loss = 50.33253187838316
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.30000000000000004
iteration 0: loss = 99.82593790608439
iteration 1: loss = 90.21313204297124
iteration 2: loss = 84.6094755565313
iteration 3: loss = 79.08733194379067
iteration 4: loss = 75.99723754979505
iteration 5: loss = 73.42793340135465
iteration 6: loss = 71.50146115171759
iteration 7: loss = 70.54446362298918
iteration 8: loss = 69.34826937460618
iteration 9: loss = 68.53421741381902
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.16
Average score for parameter after cross-validation (0.03, 0.1) : 0.29000000000000004
Cross-validating parameter (0.1, 0.03) .........
iteration 0: loss = 77.58007094936823
iteration 1: loss = 69.39955440683866
iteration 2: loss = 64.73569322772872
iteration 3: loss = 61.96565720524838
iteration 4: loss = 59.07407272964056
iteration 5: loss = 55.69174298705883
iteration 6: loss = 54.2935038236665
iteration 7: loss = 53.28615248652414
iteration 8: loss = 51.90457168233401
iteration 9: loss = 51.11603565823965
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.20000000000000004
iteration 0: loss = 77.29427263209021
iteration 1: loss = 69.6020909527413
iteration 2: loss = 64.81164812574912
iteration 3: loss = 60.26333364319137
iteration 4: loss = 57.535999114215315
iteration 5: loss = 55.35383541171872
iteration 6: loss = 53.19406569124696
iteration 7: loss = 52.035915459567775
iteration 8: loss = 50.25189652345028
iteration 9: loss = 48.74947882595022
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.36
iteration 0: loss = 89.87219220581949
iteration 1: loss = 80.73411641001486
iteration 2: loss = 75.5796444420368
iteration 3: loss = 72.97656612004035
iteration 4: loss = 70.58927392285436
iteration 5: loss = 67.47296831307632
iteration 6: loss = 66.10426373423637
iteration 7: loss = 64.51699442725162
iteration 8: loss = 62.28202383461942
iteration 9: loss = 61.36464915595061
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.15
Average score for parameter after cross-validation (0.1, 0.03) : 0.2366666666666667
Cross-validating parameter (0.1, 0.1) .........
iteration 0: loss = 105.5035804230589
iteration 1: loss = 91.51577024138058
iteration 2: loss = 82.62447964152904
iteration 3: loss = 76.64739230849881
iteration 4: loss = 72.0004610899436
iteration 5: loss = 67.1953323340974
iteration 6: loss = 64.39123597432804
iteration 7: loss = 61.111901407964275
iteration 8: loss = 59.788823104375
iteration 9: loss = 58.02120008941881
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.25000000000000006
iteration 0: loss = 65.55878889598526
iteration 1: loss = 62.02511203865143
iteration 2: loss = 59.23934701034878
iteration 3: loss = 56.995328095104014
iteration 4: loss = 55.04254284500972
iteration 5: loss = 53.36009933194594
iteration 6: loss = 52.010152784148595
iteration 7: loss = 51.40954770420967
iteration 8: loss = 50.51444790843264
iteration 9: loss = 49.40101528217535
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.29
iteration 0: loss = 115.5906682030821
iteration 1: loss = 105.61073415406517
iteration 2: loss = 96.79070602580185
iteration 3: loss = 91.99177819263103
iteration 4: loss = 86.23917039514328
iteration 5: loss = 84.65836471288017
iteration 6: loss = 81.94294140677187
iteration 7: loss = 79.92526370814832
iteration 8: loss = 75.85369202171483
iteration 9: loss = 73.46186008860894
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.11000000000000001
Average score for parameter after cross-validation (0.1, 0.1) : 0.21666666666666667
best parameter in cross-validation : (0.03, 0.1) with prec@n 0.29000000000000004
iteration 0: loss = 132.60906088048927
iteration 1: loss = 118.41867608235681
iteration 2: loss = 109.74322328947986
iteration 3: loss = 104.44191406002189
iteration 4: loss = 101.2161175736957
iteration 5: loss = 97.82027022187825
iteration 6: loss = 94.55068250778305
iteration 7: loss = 91.90844672739965
iteration 8: loss = 89.92906691914598
iteration 9: loss = 87.37864252308918
iteration 10: loss = 85.73541377686435
iteration 11: loss = 83.85818296198624
iteration 12: loss = 82.82541925005367
iteration 13: loss = 81.93139554908169
iteration 14: loss = 80.29205286794956
iteration 15: loss = 79.01123398385234
iteration 16: loss = 78.15795560313552
iteration 17: loss = 77.26416194479083
iteration 18: loss = 75.83638538131521
iteration 19: loss = 74.59343184159812
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
Mapper Map_BPR trainning for iteration 10 ...
Mapper Map_BPR trainning for iteration 11 ...
Mapper Map_BPR trainning for iteration 12 ...
Mapper Map_BPR trainning for iteration 13 ...
Mapper Map_BPR trainning for iteration 14 ...
Mapper Map_BPR trainning for iteration 15 ...
Mapper Map_BPR trainning for iteration 16 ...
Mapper Map_BPR trainning for iteration 17 ...
Mapper Map_BPR trainning for iteration 18 ...
Mapper Map_BPR trainning for iteration 19 ...
Test for fold 1 : Prec@n = 0.13999999999999999 auc = 0.3214172494172494
------------------------------------------------
Cross-validating parameter (0.03, 0.03) .........
iteration 0: loss = 74.19579076339939
iteration 1: loss = 67.63719037285351
iteration 2: loss = 63.77604205963122
iteration 3: loss = 61.87245878771538
iteration 4: loss = 59.678313047349846
iteration 5: loss = 57.977882030961744
iteration 6: loss = 56.895436923381496
iteration 7: loss = 55.94001818577986
iteration 8: loss = 55.07690806976321
iteration 9: loss = 54.16867157357475
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.2500000000000001
iteration 0: loss = 82.50836437766333
iteration 1: loss = 77.39748985282064
iteration 2: loss = 73.43256657301637
iteration 3: loss = 70.99599672684057
iteration 4: loss = 68.36963831072165
iteration 5: loss = 66.23524160883451
iteration 6: loss = 65.23012261814148
iteration 7: loss = 63.772209708046795
iteration 8: loss = 62.604272994132515
iteration 9: loss = 61.414818251687535
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.33000000000000007
iteration 0: loss = 95.28108006338633
iteration 1: loss = 87.14555763365331
iteration 2: loss = 81.94541118988928
iteration 3: loss = 78.61775979465081
iteration 4: loss = 75.56810147793645
iteration 5: loss = 73.78447795662748
iteration 6: loss = 71.8605188009369
iteration 7: loss = 70.8696734799316
iteration 8: loss = 69.27374611022304
iteration 9: loss = 67.77336817102133
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.25000000000000006
Average score for parameter after cross-validation (0.03, 0.03) : 0.2766666666666668
Cross-validating parameter (0.03, 0.1) .........
iteration 0: loss = 78.91006899489945
iteration 1: loss = 72.78784748923573
iteration 2: loss = 68.80431202482244
iteration 3: loss = 66.77846247850378
iteration 4: loss = 63.910750538417375
iteration 5: loss = 61.50988755530945
iteration 6: loss = 60.10858429456228
iteration 7: loss = 58.52261948954573
iteration 8: loss = 57.454351225766715
iteration 9: loss = 56.68080421315588
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.22000000000000006
iteration 0: loss = 105.25797692471674
iteration 1: loss = 97.80741672218296
iteration 2: loss = 88.74084131187938
iteration 3: loss = 82.67889901614966
iteration 4: loss = 80.59703802401435
iteration 5: loss = 76.24100334833047
iteration 6: loss = 73.57964593267414
iteration 7: loss = 71.17008355168647
iteration 8: loss = 69.43167598104881
iteration 9: loss = 68.53047169194633
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.28
iteration 0: loss = 113.28576656662948
iteration 1: loss = 100.35605529201194
iteration 2: loss = 92.75150015757046
iteration 3: loss = 87.97743977712969
iteration 4: loss = 84.49554842640063
iteration 5: loss = 81.76491914107613
iteration 6: loss = 79.48233445053832
iteration 7: loss = 76.66632154938478
iteration 8: loss = 74.2619153878411
iteration 9: loss = 73.17153585465405
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.33
Average score for parameter after cross-validation (0.03, 0.1) : 0.27666666666666667
Cross-validating parameter (0.1, 0.03) .........
iteration 0: loss = 79.77818896192603
iteration 1: loss = 76.57931688732829
iteration 2: loss = 72.20636899808687
iteration 3: loss = 69.99637417836918
iteration 4: loss = 68.32840532045343
iteration 5: loss = 66.45880736174175
iteration 6: loss = 65.3336225342891
iteration 7: loss = 64.56477944848005
iteration 8: loss = 63.2577017081858
iteration 9: loss = 62.31566130551285
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.12
iteration 0: loss = 92.2441407317897
iteration 1: loss = 85.06704805585038
iteration 2: loss = 80.4425431975042
iteration 3: loss = 76.7068584829817
iteration 4: loss = 73.90473903164394
iteration 5: loss = 72.46252618069184
iteration 6: loss = 70.83192885921109
iteration 7: loss = 68.66836055428635
iteration 8: loss = 67.56862141214872
iteration 9: loss = 65.82042860390791
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.33000000000000007
iteration 0: loss = 131.7653189849784
iteration 1: loss = 112.64335171227188
iteration 2: loss = 99.50429603510469
iteration 3: loss = 94.32693519134804
iteration 4: loss = 88.65777434046794
iteration 5: loss = 84.9354842339392
iteration 6: loss = 81.15412264999186
iteration 7: loss = 79.44815504947525
iteration 8: loss = 76.68485640441388
iteration 9: loss = 74.58855600710056
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.32
Average score for parameter after cross-validation (0.1, 0.03) : 0.25666666666666665
Cross-validating parameter (0.1, 0.1) .........
iteration 0: loss = 105.00270783729476
iteration 1: loss = 95.78539711925606
iteration 2: loss = 87.88917912492178
iteration 3: loss = 82.1959801022884
iteration 4: loss = 78.40661012155824
iteration 5: loss = 74.84650928476944
iteration 6: loss = 72.03689569380005
iteration 7: loss = 70.32607783948335
iteration 8: loss = 69.46196422521558
iteration 9: loss = 67.73092444355703
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 0 : 0.31
iteration 0: loss = 104.75328684239847
iteration 1: loss = 92.76361799120974
iteration 2: loss = 83.7514835412139
iteration 3: loss = 79.54458443425335
iteration 4: loss = 75.70049530476453
iteration 5: loss = 74.55342923995234
iteration 6: loss = 71.24261008571139
iteration 7: loss = 69.53205411998351
iteration 8: loss = 67.71529477448134
iteration 9: loss = 66.378914600994
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 1 : 0.28
iteration 0: loss = 96.78154580803877
iteration 1: loss = 87.0390388581543
iteration 2: loss = 81.94834136658476
iteration 3: loss = 77.01939147562315
iteration 4: loss = 75.77481304532236
iteration 5: loss = 72.71433939151322
iteration 6: loss = 70.97237053251857
iteration 7: loss = 69.00370803720631
iteration 8: loss = 67.14696506582621
iteration 9: loss = 66.14510695421757
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
prec@5 of cross-validation fold 2 : 0.2900000000000001
Average score for parameter after cross-validation (0.1, 0.1) : 0.2933333333333334
best parameter in cross-validation : (0.1, 0.1) with prec@n 0.2933333333333334
iteration 0: loss = 162.53107728410265
iteration 1: loss = 146.00199522595452
iteration 2: loss = 135.2137646678167
iteration 3: loss = 128.5108453845093
iteration 4: loss = 122.13667252738139
iteration 5: loss = 117.27340499473476
iteration 6: loss = 114.85333764557294
iteration 7: loss = 112.1953093693822
iteration 8: loss = 109.69915951079139
iteration 9: loss = 106.81008554792666
iteration 10: loss = 104.86541068265062
iteration 11: loss = 101.5011161721189
iteration 12: loss = 100.47343064330883
iteration 13: loss = 98.59792482656967
iteration 14: loss = 97.45644644760068
iteration 15: loss = 95.5182478344106
iteration 16: loss = 94.55338858008751
iteration 17: loss = 93.60006015457324
iteration 18: loss = 92.31262570964589
iteration 19: loss = 91.9928407247335
Mapper Map_BPR trainning for iteration 0 ...
Mapper Map_BPR trainning for iteration 1 ...
Mapper Map_BPR trainning for iteration 2 ...
Mapper Map_BPR trainning for iteration 3 ...
Mapper Map_BPR trainning for iteration 4 ...
Mapper Map_BPR trainning for iteration 5 ...
Mapper Map_BPR trainning for iteration 6 ...
Mapper Map_BPR trainning for iteration 7 ...
Mapper Map_BPR trainning for iteration 8 ...
Mapper Map_BPR trainning for iteration 9 ...
Mapper Map_BPR trainning for iteration 10 ...
Mapper Map_BPR trainning for iteration 11 ...
Mapper Map_BPR trainning for iteration 12 ...
Mapper Map_BPR trainning for iteration 13 ...
Mapper Map_BPR trainning for iteration 14 ...
Mapper Map_BPR trainning for iteration 15 ...
Mapper Map_BPR trainning for iteration 16 ...
Mapper Map_BPR trainning for iteration 17 ...
Mapper Map_BPR trainning for iteration 18 ...
Mapper Map_BPR trainning for iteration 19 ...
Test for fold 2 : Prec@n = 0.19 auc = 0.33380439005439005
------------------------------------------------
avg_prec =  0.23666666666666666 , avg_auc =  0.385108638275305
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="extra-notes">
<h2>Extra Notes<a class="headerlink" href="#extra-notes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h3>
<p>Training a hypothetical factorization model with k = 2 yields two matrices consisting of the user and item factor vectors, respectively:</p>
<p><center><img src='_images/T847725_1.png'></center></p></div>
<div class="section" id="loss-function">
<h3>Loss function<a class="headerlink" href="#loss-function" title="Permalink to this headline">¶</a></h3>
<p>The general form of score estimation by mapping from item attributes to item factors is:</p>
<div class="math notranslate nohighlight">
\[\hat{y}_{ui} := \sum_{f=1}^k w_{uf}\phi_f(a_i^I) = \langle w_u,\phi(a_i^I) \rangle\]</div>
</div>
</div>
<div class="section" id="citations">
<h2>Citations<a class="headerlink" href="#citations" title="Permalink to this headline">¶</a></h2>
<p>Learning Attribute to Feature Mappings for Cold-Start Recommendations. Lucas Drumond, Christoph Freudenthaler, Steffen Rendle, Lars Schmidt-Thieme. 2010. ICDM. <a class="reference external" href="https://bit.ly/3Eh4NEK">https://bit.ly/3Eh4NEK</a></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sparsh-ai/coldstart-recsys",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="L281872_Cold_Start_Recommendations.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Cold-Start Recommendations</p>
            </div>
        </a>
    </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>